{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files\n",
    "##### train.csv\n",
    "* building_id - Foreign key for the building metadata.\n",
    "* meter - The meter id code. Read as {0: electricity, 1: chilledwater, 2: steam, 3: hotwater}. Not every building has all meter types.\n",
    "* timestamp - When the measurement was taken\n",
    "* meter_reading - The target variable. Energy consumption in kWh (or equivalent). Note that this is real data with measurement error, which we expect will impose a baseline level of modeling error. UPDATE: as discussed here, the site 0 electric meter readings are in kBTU.\n",
    "\n",
    "##### building_meta.csv\n",
    "* site_id - Foreign key for the weather files.\n",
    "* building_id - Foreign key for training.csv\n",
    "* primary_use - Indicator of the primary category of activities for the building based on EnergyStar property type definitions\n",
    "* square_feet - Gross floor area of the building\n",
    "* year_built - Year building was opened\n",
    "* floor_count - Number of floors of the building\n",
    "\n",
    "##### weather_[train/test].csv\n",
    "Weather data from a meteorological station as close as possible to the site.\n",
    "\n",
    "* site_id\n",
    "* air_temperature - Degrees Celsius\n",
    "* cloud_coverage - Portion of the sky covered in clouds, in oktas\n",
    "* dew_temperature - Degrees Celsius\n",
    "* precip_depth_1_hr - Millimeters\n",
    "* sea_level_pressure - Millibar/hectopascals\n",
    "* wind_direction - Compass direction (0-360)\n",
    "* wind_speed - Meters per second\n",
    "\n",
    "##### test.csv\n",
    "The submission files use row numbers for ID codes in order to save space on the file uploads. test.csv has no feature data; it exists so you can get your predictions into the correct order.\n",
    "* row_id - Row id for your submission file\n",
    "* building_id - Building id code\n",
    "* meter - The meter id code\n",
    "* timestamp - Timestamps for the test data period\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"datasets/ashrae-energy-prediction/train_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 732.62 Mb (56.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 10 columns):\n",
      "building_id        int16\n",
      "meter              int8\n",
      "timestamp          object\n",
      "meter_reading      float32\n",
      "site_id            int8\n",
      "primary_use        object\n",
      "square_feet        int32\n",
      "air_temperature    float16\n",
      "cloud_coverage     float16\n",
      "dew_temperature    float16\n",
      "dtypes: float16(3), float32(1), int16(1), int32(1), int8(2), object(2)\n",
      "memory usage: 655.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop('Unnamed: 0',axis=1)\n",
    "print(df_train.shape)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id              0\n",
       "meter                    0\n",
       "timestamp                0\n",
       "meter_reading            0\n",
       "site_id                  0\n",
       "primary_use              0\n",
       "square_feet              0\n",
       "air_temperature      96658\n",
       "cloud_coverage     8825365\n",
       "dew_temperature     100140\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2147.36 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_test.shape)\n",
    "# df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['meter'].unique())\n",
    "# df_train['meter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meter_percent = df_train.meter.value_counts('percent')*100\n",
    "# print(meter_percent)\n",
    "# meter_percent.plot(kind='bar')\n",
    "# plt.title(\"Use of meter type in %\")\n",
    "# plt.ylabel(\"Percentage\")\n",
    "# plt.xlabel(\"Meter\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['site_id'].unique())\n",
    "# df_train['site_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.groupby('site_id')['building_id'].count().plot(kind='bar')\n",
    "# plt.title(\"No. of building by site id\")\n",
    "# plt.ylabel(\"No. of building\")\n",
    "# plt.xlabel(\"Site ID\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(y='primary_use',data=df_train)\n",
    "# plt.title(\"Count of building with respect to primary use\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['year_built'].unique())\n",
    "# print(df_train['year_built'].value_counts())\n",
    "# sns.distplot(df_train['year_built'].dropna(),bins=24,kde=False)\n",
    "# plt.title('Distribution of buildings by the year they are built')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_train['air_temperature'], hist=True, kde=True,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df_train['dew_temperature'], bins=30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['timestamp'] = pd.to_datetime(df_train['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,10))\n",
    "# sns.boxplot(x='primary_use', y='square_feet', data=df_train)\n",
    "# plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_train['wind_speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['wind_direction'].unique())\n",
    "# # print(df_train['wind_direction'].value_counts())\n",
    "# sns.boxplot(df_train['wind_direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# sns.boxplot(df_train['site_id'], df_train['meter_reading'], showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_train['meter'], df_train['meter_reading'], showfliers=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(df_train['primary_use'], df_train['meter_reading'], showfliers=False)\n",
    "# plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=df_train.groupby('air_temperature')['meter_reading'].mean().to_frame()\n",
    "# plt.figure(figsize=(15,10))\n",
    "# sns.scatterplot(m.index,m['meter_reading'])\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=df_train.groupby('dew_temperature')['meter_reading'].mean().to_frame()\n",
    "# plt.figure(figsize=(15,10))\n",
    "# sns.scatterplot(m.index,m['meter_reading'])\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.copy()\n",
    "test = df_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values={'air_temperature':np.around(np.mean(train['air_temperature']),decimals=1),'cloud_coverage':np.around(np.mean(train['cloud_coverage'])),'dew_temperature':np.around(np.mean(train['dew_temperature']),decimals=1)}\n",
    "train=train.fillna(value=nan_values)\n",
    "nan_values={'air_temperature':np.around(np.mean(test['air_temperature']),decimals=1),'cloud_coverage':np.around(np.mean(test['cloud_coverage'])),'dew_temperature':np.around(np.mean(test['dew_temperature']),decimals=1)}\n",
    "test=test.fillna(value=nan_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"timestamp\"] = pd.to_datetime(df_train[\"timestamp\"])\n",
    "# df_train[\"hour\"] = df_train[\"timestamp\"].dt.hour\n",
    "# df_train[\"day\"] = df_train[\"timestamp\"].dt.day\n",
    "# df_train[\"weekend\"] = df_train[\"timestamp\"].dt.weekday\n",
    "# df_train[\"month\"] = df_train[\"timestamp\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"timestamp\"] = pd.to_datetime(df_train[\"timestamp\"])\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"day\"] = train[\"timestamp\"].dt.day\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "train = train.drop([\"timestamp\",\"Unnamed: 0\"], axis = 1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "train[\"primary_use\"] = le.fit_transform(train[\"primary_use\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [\"building_id\", \"primary_use\", \"hour\", \"day\", \"weekend\", \"month\", \"meter\"]\n",
    "\n",
    "drop_cols = [\"precip_depth_1_hr\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\"]\n",
    "\n",
    "numericals = [\"square_feet\", \"air_temperature\", \"cloud_coverage\",\n",
    "              \"dew_temperature\"]\n",
    "\n",
    "feat_cols = categoricals + numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log1p(train[\"meter_reading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(drop_cols + [\"site_id\",\"floor_count\",\"meter_reading\"], axis = 1)\n",
    "#train.fillna(-999, inplace=True)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (train.shape)\n",
    "train[feat_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "error = 0\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train, target)):\n",
    "\n",
    "    print ('Training FOLD ',fold,'\\n')\n",
    "    print('Train index:','\\tfrom:',train_index.min(),'\\tto:',train_index.max())\n",
    "    print('Valid index:','\\tfrom:',val_index.min(),'\\tto:',val_index.max(),'\\n')\n",
    "    \n",
    "    train_X = train[feat_cols].iloc[train_index]\n",
    "    val_X = train[feat_cols].iloc[val_index]\n",
    "    train_y = target.iloc[train_index]\n",
    "    val_y = target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    \n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'rmse'},\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9, \n",
    "        'alpha': 0.1, \n",
    "        'lambda': 0.1\n",
    "            }\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                    categorical_feature = categoricals,\n",
    "                valid_sets=(lgb_train, lgb_eval),\n",
    "               early_stopping_rounds=20,\n",
    "               verbose_eval = 20)\n",
    "\n",
    "    y_pred = gbm.predict(val_X, num_iteration=gbm.best_iteration)\n",
    "    error += np.sqrt(mean_squared_error(y_pred, (val_y)))/num_folds\n",
    "    \n",
    "    print('\\nFold',fold,' Score: ',np.sqrt(mean_squared_error(y_pred, val_y)))\n",
    "    #print('RMSLE: ', rmsle(y_pred, val_y))\n",
    "    #print('RMSLE_2: ', np.sqrt(mean_squared_log_error(y_pred, (val_y))))\n",
    "\n",
    "    del train_X, val_X, train_y, val_y, lgb_train, lgb_eval\n",
    "    gc.collect()\n",
    "\n",
    "    print (20*'---')\n",
    "    break\n",
    "    \n",
    "print('CV error: ',error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(gbm.feature_importance(), gbm.feature_name()),reverse = True), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour.astype(np.uint8)\n",
    "test[\"day\"] = test[\"timestamp\"].dt.day.astype(np.uint8)\n",
    "test[\"weekend\"] = test[\"timestamp\"].dt.weekday.astype(np.uint8)\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month.astype(np.uint8)\n",
    "test = test[feat_cols]\n",
    "le = preprocessing.LabelEncoder()\n",
    "test[\"primary_use\"] = le.fit_transform(test[\"primary_use\"])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "i=0\n",
    "res=[]\n",
    "step_size = 50000 \n",
    "for j in tqdm(range(int(np.ceil(test.shape[0]/50000)))):\n",
    "    res.append(np.expm1(gbm.predict(test.iloc[i:i+step_size])))\n",
    "    i+=step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.concatenate(res)\n",
    "sub = pd.read_csv(\"../datasets/ashrae-energy-prediction/sample_submission.csv\")\n",
    "# count_row_sub = sub.shape[0]\n",
    "# sub = sub.loc[:count_row_sub*0.1-1]\n",
    "sub[\"meter_reading\"] = res\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, \n",
    "                                                    random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
